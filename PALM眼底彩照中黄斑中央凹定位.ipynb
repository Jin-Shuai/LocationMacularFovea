{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方案说明\n",
    "本方案是一个简单的根据0基础入门的示例中的识别手写数字改写而成的黄斑定位程序。<br />\n",
    "本方案从头到尾直接运行即可，整体布局为 **数据获取 -> 函数定义 -> 训练 -> 预测**。<br />\n",
    "\n",
    "# 题目分析\n",
    "## 难点<br />\n",
    "&ensp;&ensp;题目要求为在一组图片上找到黄斑中心，但是图片的大小不一，每张图片对应的黄斑中心的取值范围也随着图片大小的变化而变化，从而缺乏一个统一的标准。\n",
    "    \n",
    "## 解决方案<br />\n",
    "&ensp;&ensp;指定缩放尺寸，将所有的图片均缩放到指定尺寸。对于中心点坐标，将所有的中心点坐标转化为中心点在xy轴的百分比位置，如目标点在最中间则认为横纵分别为0.5。最后再将预测后的小数还原为整数即可得到真实图片上的像素点坐标。\n",
    "\n",
    "## 具体实现策略<br />\n",
    "&ensp;&ensp;（本程序没有实现异步读取，直接做了最基础的读数据，运行。最后会在./work/Fovea_Localization_Results.csv中保存测试结果。）<br />\n",
    "&ensp;&ensp;1. 依次读取训练图片，将图片转为灰度模式，将图片缩放到指定尺寸，将黄斑中心转化到[0,1]。直接使用dataframe记录图片信息和黄斑中心分别作为输入和输出。<br />\n",
    "&ensp;&ensp;2. 构造神经网络，这部分直接参考0基础入门的示例中的识别手写数字。[https://www.paddlepaddle.org.cn/tutorials/projectdetail/2182025]<br />\n",
    "&ensp;&ensp;3. 训练数据，将之前保存过的dataframe转化为tensor直接训练即可，本程序将xy坐标分开进行训练。<br />\n",
    "&ensp;&ensp;4. 依次读取测试图片，将图片转为灰度模式，将图片缩放到指定尺寸。直接使用dataframe记录图片信息和原始图片尺寸，原始图片尺寸用于将预测结果转化为真实坐标。<br />\n",
    "&ensp;&ensp;5. 预测，并将预测后的值转化到真实坐标上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 程序开始\n",
    "## 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-19T09:08:56.812098Z",
     "iopub.status.busy": "2021-12-19T09:08:56.811743Z",
     "iopub.status.idle": "2021-12-19T09:09:23.640136Z",
     "shell.execute_reply": "2021-12-19T09:09:23.639210Z",
     "shell.execute_reply.started": "2021-12-19T09:08:56.812063Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading start!\n",
      "Downloading end!\n"
     ]
    }
   ],
   "source": [
    "# 下载数据\n",
    "import urllib \n",
    "import requests   \n",
    "import os\n",
    "url = 'https://bj.bcebos.com/v1/dataset-bj/%E5%8C%BB%E7%96%97%E6%AF%94%E8%B5%9B/%E5%B8%B8%E8%A7%84%E8%B5%9B%EF%BC%9APALM%E7%9C%BC%E5%BA%95%E5%BD%A9%E7%85%A7%E4%B8%AD%E9%BB%84%E6%96%91%E4%B8%AD%E5%A4%AE%E5%87%B9%E5%AE%9A%E4%BD%8D.zip'  \n",
    "\n",
    "if not os.path.exists('./work/Train_and_test.zip'):\n",
    "    print(\"Downloading start!\")\n",
    "    urllib.request.urlretrieve(url, \"./work/Train_and_test.zip\")  \n",
    "    print(\"Downloading end!\")\n",
    "else:\n",
    "    print(\"Already Downloading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-19T09:09:29.725421Z",
     "iopub.status.busy": "2021-12-19T09:09:29.724567Z",
     "iopub.status.idle": "2021-12-19T09:09:49.693684Z",
     "shell.execute_reply": "2021-12-19T09:09:49.692125Z",
     "shell.execute_reply.started": "2021-12-19T09:09:29.725347Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 解压数据\n",
    "! unzip -oq ./work/Train_and_test.zip -d ./work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义（包，变量，函数）<br />\n",
    "\n",
    "自定义变量包括:<br />\n",
    "&ensp;&ensp;image_size \t\t # 缩放图片的大小<br />\n",
    "&ensp;&ensp;m_ite\t   \t\t# 训练的迭代次数，相当于基础教程里的epoch<br />\n",
    "&ensp;&ensp;model_save_dir\t # 训练后的模型保存地址<br />\n",
    "\n",
    "自定义函数包括:<br />\n",
    "&ensp;&ensp;get_train_image\t\t读取训练图片，缩放图片到指定大小<br />\n",
    "&ensp;&ensp;get_test_image\t\t读取测试图片，缩放图片到指定大小<br />\n",
    "&ensp;&ensp;Mymodel\t\t\t\t定义CNN网络<br />\n",
    "&ensp;&ensp;train\t\t\t\t对网络进行训练<br />\n",
    "&ensp;&ensp;test\t\t\t\t对网络进行测试并且写入.csv<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-19T09:10:10.098812Z",
     "iopub.status.busy": "2021-12-19T09:10:10.098436Z",
     "iopub.status.idle": "2021-12-19T09:10:11.677712Z",
     "shell.execute_reply": "2021-12-19T09:10:11.676724Z",
     "shell.execute_reply.started": "2021-12-19T09:10:10.098769Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# 定义缩放的大小，训练迭代次数，模型保存目录\n",
    "global image_size\n",
    "image_size = 96\n",
    "m_ite=5000\n",
    "model_save_dir='./work/mymodel'\n",
    "last_model_dir='./work/mymodel'\n",
    "\n",
    "def get_train_image(image_size):\n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "    # 读xlsx\n",
    "    df = pd.read_excel('./work/常规赛：PALM眼底彩照中黄斑中央凹定位/Train/Fovea_Location_train.xlsx')\n",
    "    # 定义变量用于保存图片的原始大小和修改后的中心点坐标\n",
    "    df['ori_width'] = 0\n",
    "    df['ori_height'] = 0\n",
    "    df['changed_x'] = 0.0\n",
    "    df['changed_y'] = 0.0\n",
    "    im_list = []\n",
    "    for i in range(len(df)):  # df[df.columns[0]]:\n",
    "        if i % 50 == 0:\n",
    "            print(str(i / len(df) * 100) + '% finished')\n",
    "        im = Image.open('./work/常规赛：PALM眼底彩照中黄斑中央凹定位/Train/fundus_image/' + df[df.columns[0]][i])\n",
    "        df['ori_width'][i] = np.array(im).shape[1]  # 列对应横向宽度，行对应纵向宽度\n",
    "        df['ori_height'][i] = np.array(im).shape[0]\n",
    "        df['changed_x'][i] = df['Fovea_X'][i]/np.array(im).shape[1]\n",
    "        df['changed_y'][i] = df['Fovea_Y'][i]/np.array(im).shape[0]\n",
    "        #转化为灰度图并缩小，保存在列表中\n",
    "        im = im.convert('L')\n",
    "        im = im.resize((image_size, image_size), Image.ANTIALIAS)\n",
    "        im = np.array(im).reshape(1, -1).astype(np.float32)\n",
    "        im_list.append(im.tolist()[0])\n",
    "    print(str(1 * 100) + '% finished')\n",
    "    im_record = np.array(im_list)\n",
    "    df2 = pd.DataFrame(im_record)\n",
    "    pd.set_option('mode.chained_assignment', \"raise\")\n",
    "    # return train_infor, train_input\n",
    "    # 返回图片的标签信息和图片向量\n",
    "    return df, df2\n",
    "\n",
    "def get_test_image(image_size):\n",
    "    # read the test_infor\n",
    "    mylist=[]\n",
    "    im_list = []\n",
    "    for i in range(400):\n",
    "        if i % 50 == 0:\n",
    "            print(str(i / 400 * 100) + '% finished')\n",
    "        target_pic_name='T' + ('%04d' % (i+1)) + '.jpg'\n",
    "        # 无法直接从csv中读取，所以手动生成向量\n",
    "        tmplist=[target_pic_name,0.0,0.0,0,0,0.0,0.0]\n",
    "        im = Image.open('./work/常规赛：PALM眼底彩照中黄斑中央凹定位/PALM-Testing400-Images/' + target_pic_name)\n",
    "        tmplist[3] = np.array(im).shape[1]  # 列对应横向宽度，行对应纵向宽度\n",
    "        tmplist[4] = np.array(im).shape[0]\n",
    "        im = im.convert('L')\n",
    "        im = im.resize((image_size, image_size), Image.ANTIALIAS)\n",
    "        im = np.array(im).reshape(1, -1).astype(np.float32)\n",
    "        im_list.append(im.tolist()[0])\n",
    "\n",
    "        mylist.append(tmplist)\n",
    "    print(str(1 * 100) + '% finished')\n",
    "    test_df = pd.DataFrame.from_records(mylist, columns=['FileName', 'Fovea_X', 'Fovea_Y', 'ori_width', 'ori_height', 'changed_x', 'changed_y'])\n",
    "    im_record = np.array(im_list)\n",
    "    df_test_input = pd.DataFrame(im_record)\n",
    "    pd.set_option('mode.chained_assignment', \"raise\")\n",
    "    # return test_infor, test_input\n",
    "    return test_df, df_test_input\n",
    "\n",
    "#定义模型，本模型参考了https://www.paddlepaddle.org.cn/tutorials/projectdetail/2182025\n",
    "class Mymodel(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Mymodel, self).__init__()\n",
    "        global image_size\n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "        self.conv1 = Conv2D(in_channels=1, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义卷积层，输出特征通道out_channels设置为20，卷积核的大小kernel_size为5，卷积步长stride=1，padding=2\n",
    "        self.conv2 = Conv2D(in_channels=20, out_channels=20, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义池化层，池化核的大小kernel_size为2，池化步长为2\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义全连接层，输出维度是2\n",
    "        # 计算维度\n",
    "        tmp=np.zeros([image_size,image_size], dtype='float32', order='C')\n",
    "        tmp = np.array(tmp).reshape(1, 1, image_size, image_size).astype(np.float32)\n",
    "        tmp=paddle.to_tensor(tmp)\n",
    "        tmp1 = self.conv1(tmp)\n",
    "        tmp2 = self.max_pool1(tmp1)\n",
    "        tmp3 = self.conv2(tmp2)\n",
    "        tmp4 = self.max_pool2(tmp3)\n",
    "        liner_input_num=1\n",
    "        for i in range(len(tmp4.shape)):\n",
    "            liner_input_num*=tmp4.shape[i]\n",
    "        self.fc = Linear(in_features=liner_input_num, out_features=5000)\n",
    "        self.fc2 = Linear(in_features=5000, out_features=1000)\n",
    "        self.fc3 = Linear(in_features=1000, out_features=1)\n",
    "\n",
    "    # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\n",
    "    def forward(self, inputs):\n",
    "         x = self.conv1(inputs)\n",
    "         x = F.relu(x)\n",
    "         x = self.max_pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = F.relu(x)\n",
    "         x = self.max_pool2(x)\n",
    "         x = paddle.reshape(x, [x.shape[0], -1])\n",
    "         x = self.fc(x)\n",
    "         x = F.relu6(x)\n",
    "         x =self.fc2(x)\n",
    "         x = F.tanh(x)\n",
    "         x =self.fc3(x)\n",
    "         return x\n",
    "\n",
    "# 定义训练\n",
    "def train(model1,model2, train_infor, train_input,eval_infor,eval_input,image_size,m_ite):\n",
    "    # 将数据转化为四维矩阵格式，并归一到0-1\n",
    "    train_im = paddle.to_tensor(train_input.values.astype('float32')/255)\n",
    "    train_im = paddle.reshape(train_im,[train_im.shape[0], 1, image_size, image_size])\n",
    "    train_lab_x = train_infor[['changed_x']]\n",
    "    train_lab_x = paddle.to_tensor(train_lab_x.values.astype('float32'))\n",
    "    train_lab_y = train_infor[['changed_y']]\n",
    "    train_lab_y = paddle.to_tensor(train_lab_y.values.astype('float32'))\n",
    "\n",
    "    eval_im = paddle.to_tensor(eval_input.values.astype('float32')/255)\n",
    "    eval_im = paddle.reshape(eval_im,[eval_im.shape[0], 1, image_size, image_size])\n",
    "    eval_lab_x = eval_infor[['changed_x']]\n",
    "    eval_lab_x = paddle.to_tensor(eval_lab_x.values.astype('float32'))\n",
    "    eval_lab_y = eval_infor[['changed_y']]\n",
    "    eval_lab_y = paddle.to_tensor(eval_lab_y.values.astype('float32'))\n",
    "\n",
    "    # 定义学习器\n",
    "    opt1 = paddle.optimizer.Adam(learning_rate=0.001, weight_decay=paddle.regularizer.L2Decay(coeff=1e-5),\n",
    "                                parameters=model1.parameters())\n",
    "    opt2 = paddle.optimizer.Adam(learning_rate=0.001, weight_decay=paddle.regularizer.L2Decay(coeff=1e-5),\n",
    "                                parameters=model2.parameters())\n",
    "\n",
    "    print('init train!')\n",
    "    \n",
    "    best_loss_x=1000\n",
    "    best_loss_y=1000\n",
    "    best_x_ite=-1\n",
    "    best_y_ite=-1\n",
    "\n",
    "    # 训练\n",
    "    for i in range(m_ite):\n",
    "        predicts1 = model1(train_im)\n",
    "        predicts2 = model2(train_im)\n",
    "        loss1 = F.square_error_cost(predicts1, train_lab_x)\n",
    "        loss2 = F.square_error_cost(predicts2, train_lab_y)\n",
    "        avg_loss1 = paddle.mean(loss1)\n",
    "        avg_loss2 = paddle.mean(loss2)\n",
    "\n",
    "        avg_loss1.backward()\n",
    "        avg_loss2.backward()\n",
    "        opt1.step()\n",
    "        opt1.clear_grad()\n",
    "        opt2.step()\n",
    "        opt2.clear_grad()\n",
    "        \n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "\n",
    "        predictsx = model1(eval_im)\n",
    "        predictsy = model2(eval_im)\n",
    "        lossx = F.square_error_cost(predictsx, eval_lab_x)\n",
    "        lossy = F.square_error_cost(predictsy, eval_lab_y)\n",
    "        avg_lossx = paddle.mean(lossx)\n",
    "        avg_lossy = paddle.mean(lossy)\n",
    "        \n",
    "        if avg_lossx.numpy()<best_loss_x:\n",
    "            best_loss_x=avg_lossx.numpy()\n",
    "            paddle.save(model1.state_dict(), model_save_dir+'x')\n",
    "            best_x_ite=i\n",
    "        if avg_lossy.numpy()<best_loss_y:\n",
    "            best_loss_y=avg_lossy.numpy()\n",
    "            paddle.save(model2.state_dict(), model_save_dir+'y')\n",
    "            best_y_ite=i\n",
    "        \n",
    "        model1.train()\n",
    "        model2.train()\n",
    "        \n",
    "        if i%100==0:\n",
    "            print(\"ite: {}, x los: {}, y los: {}, best x ite: {}, best y ite: {}\".format(i,avg_loss1.numpy(),avg_loss2.numpy(),best_x_ite,best_y_ite))\n",
    "\n",
    "#定义测试\n",
    "def test(model1, model2, test_infor, test_input ,image_size):\n",
    "    print('test_start')\n",
    "    # param_dict = paddle.load('./PALM')\n",
    "    # model.load_dict(param_dict)\n",
    "    \n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "\n",
    "    test_im = paddle.to_tensor(test_input.values.astype('float32')/255)\n",
    "    test_im = paddle.reshape(test_im,[test_im.shape[0], 1, image_size, image_size])\n",
    "    predicts1 = model1(test_im)\n",
    "    predicts1 = predicts1.numpy()\n",
    "    predicts2 = model2(test_im)\n",
    "    predicts2 = predicts2.numpy()\n",
    "\n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "    #将预测的点还原为图片上的坐标\n",
    "    for i in range(400):\n",
    "        test_infor['changed_x'][i]=predicts1[i][0]\n",
    "        test_infor['changed_y'][i]=predicts2[i][0]\n",
    "        test_infor['Fovea_X'][i] = predicts1[i][0]*test_infor['ori_width'][i]\n",
    "        test_infor['Fovea_Y'][i] = predicts2[i][0]*test_infor['ori_height'][i]\n",
    "    pd.set_option('mode.chained_assignment', 'raise')\n",
    "    \n",
    "    #写文件\n",
    "    final_df=test_infor[['FileName','Fovea_X','Fovea_Y']]\n",
    "    final_df.to_csv('./work/Fovea_Localization_Results.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正式进行训练和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_train_image!\n",
      "0.0% finished\n",
      "6.25% finished\n",
      "12.5% finished\n",
      "18.75% finished\n",
      "25.0% finished\n",
      "31.25% finished\n",
      "37.5% finished\n",
      "43.75% finished\n",
      "50.0% finished\n",
      "56.25% finished\n",
      "62.5% finished\n",
      "68.75% finished\n",
      "75.0% finished\n",
      "81.25% finished\n",
      "87.5% finished\n",
      "93.75% finished\n",
      "100% finished\n",
      "train infor gotten!\n"
     ]
    }
   ],
   "source": [
    "#获得训练数据\n",
    "print(\"get_train_image!\")\n",
    "train_infor, train_input=get_train_image(image_size)\n",
    "print(\"train infor gotten!\")\n",
    "\n",
    "train_infor.to_csv('train_infor.csv',index=None)\n",
    "train_input.to_csv('train_input.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_infor=pd.read_csv('train_infor.csv')\n",
    "train_input=pd.read_csv('train_input.csv')\n",
    "\n",
    "train_num=len(train_infor)\n",
    "eval_percent=0.2;\n",
    "cut_point=int(train_num*eval_percent)\n",
    "\n",
    "index=list(range(train_num))\n",
    "random.shuffle(index)\n",
    "\n",
    "eval_infor=train_infor.iloc[index[:cut_point],:]\n",
    "eval_input=train_input.iloc[index[:cut_point],:]\n",
    "train_infor=train_infor.iloc[index[cut_point:],:]\n",
    "train_input=train_input.iloc[index[cut_point:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n",
      "init train!\n",
      "ite: 0, x los: [0.4707266], y los: [0.44537887], best x ite: -1, best y ite: -1\n",
      "ite: 100, x los: [0.00702699], y los: [0.00342633], best x ite: 93, best y ite: 73\n",
      "ite: 200, x los: [0.00246863], y los: [0.00237697], best x ite: 149, best y ite: 73\n",
      "ite: 300, x los: [0.00122925], y los: [0.00207924], best x ite: 149, best y ite: 73\n",
      "ite: 400, x los: [0.00073432], y los: [0.00170266], best x ite: 149, best y ite: 73\n",
      "ite: 500, x los: [0.00097957], y los: [0.00152692], best x ite: 149, best y ite: 73\n",
      "ite: 600, x los: [0.00043496], y los: [0.00146891], best x ite: 149, best y ite: 73\n",
      "ite: 700, x los: [0.00032016], y los: [0.00142753], best x ite: 149, best y ite: 73\n",
      "ite: 800, x los: [0.0003557], y los: [0.00139217], best x ite: 149, best y ite: 73\n",
      "ite: 900, x los: [0.00028052], y los: [0.00135927], best x ite: 149, best y ite: 73\n",
      "ite: 1000, x los: [0.00020784], y los: [0.00132983], best x ite: 149, best y ite: 73\n",
      "ite: 1100, x los: [0.00022118], y los: [0.00130157], best x ite: 149, best y ite: 73\n",
      "ite: 1200, x los: [0.00023496], y los: [0.00127348], best x ite: 149, best y ite: 73\n",
      "ite: 1300, x los: [0.00015958], y los: [0.00124554], best x ite: 149, best y ite: 73\n",
      "ite: 1400, x los: [0.00015246], y los: [0.00121425], best x ite: 149, best y ite: 73\n",
      "ite: 1500, x los: [0.00014346], y los: [0.00119084], best x ite: 149, best y ite: 73\n",
      "ite: 1600, x los: [0.00018918], y los: [0.0011696], best x ite: 149, best y ite: 73\n",
      "ite: 1700, x los: [0.0001528], y los: [0.00115187], best x ite: 149, best y ite: 73\n",
      "ite: 1800, x los: [0.00011723], y los: [0.0011344], best x ite: 149, best y ite: 73\n",
      "ite: 1900, x los: [0.00044245], y los: [0.00111968], best x ite: 149, best y ite: 73\n",
      "ite: 2000, x los: [0.00010732], y los: [0.00110474], best x ite: 149, best y ite: 73\n",
      "ite: 2100, x los: [9.642348e-05], y los: [0.0010899], best x ite: 149, best y ite: 73\n",
      "ite: 2200, x los: [0.00057364], y los: [0.00107748], best x ite: 149, best y ite: 73\n",
      "ite: 2300, x los: [0.00010906], y los: [0.00106771], best x ite: 149, best y ite: 73\n",
      "ite: 2400, x los: [0.00099809], y los: [0.00105921], best x ite: 149, best y ite: 73\n",
      "ite: 2500, x los: [0.00010079], y los: [0.00103569], best x ite: 149, best y ite: 73\n",
      "ite: 2600, x los: [8.4066705e-05], y los: [0.00098688], best x ite: 149, best y ite: 73\n",
      "ite: 2700, x los: [7.795732e-05], y los: [0.0009532], best x ite: 149, best y ite: 73\n",
      "ite: 2800, x los: [7.321919e-05], y los: [0.0009189], best x ite: 149, best y ite: 73\n",
      "ite: 2900, x los: [7.0469054e-05], y los: [0.00087874], best x ite: 149, best y ite: 73\n",
      "ite: 3000, x los: [7.238675e-05], y los: [0.00083316], best x ite: 149, best y ite: 73\n",
      "ite: 3100, x los: [0.00010602], y los: [0.00079127], best x ite: 149, best y ite: 73\n",
      "ite: 3200, x los: [0.0001072], y los: [0.00075284], best x ite: 149, best y ite: 73\n",
      "ite: 3300, x los: [0.0001272], y los: [0.00071847], best x ite: 149, best y ite: 73\n",
      "ite: 3400, x los: [6.39018e-05], y los: [0.0006895], best x ite: 149, best y ite: 73\n",
      "ite: 3500, x los: [8.872613e-05], y los: [0.00066644], best x ite: 149, best y ite: 73\n",
      "ite: 3600, x los: [0.00163438], y los: [0.00064955], best x ite: 149, best y ite: 73\n",
      "ite: 3700, x los: [5.7955018e-05], y los: [0.00063425], best x ite: 149, best y ite: 73\n",
      "ite: 3800, x los: [5.280038e-05], y los: [0.00062315], best x ite: 149, best y ite: 73\n",
      "ite: 3900, x los: [0.00019647], y los: [0.00061545], best x ite: 149, best y ite: 73\n",
      "ite: 4000, x los: [9.795663e-05], y los: [0.00060725], best x ite: 149, best y ite: 73\n",
      "ite: 4100, x los: [0.00043969], y los: [0.00060101], best x ite: 149, best y ite: 73\n",
      "ite: 4200, x los: [6.146315e-05], y los: [0.00059263], best x ite: 149, best y ite: 73\n",
      "ite: 4300, x los: [5.311947e-05], y los: [0.00058715], best x ite: 149, best y ite: 73\n",
      "ite: 4400, x los: [4.8755515e-05], y los: [0.00058246], best x ite: 149, best y ite: 73\n",
      "ite: 4500, x los: [4.5548004e-05], y los: [0.00057532], best x ite: 149, best y ite: 73\n",
      "ite: 4600, x los: [4.8195543e-05], y los: [0.00056988], best x ite: 149, best y ite: 73\n",
      "ite: 4700, x los: [4.429978e-05], y los: [0.00056243], best x ite: 149, best y ite: 73\n",
      "ite: 4800, x los: [0.00603458], y los: [0.00055749], best x ite: 149, best y ite: 73\n",
      "ite: 4900, x los: [6.996642e-05], y los: [0.00055269], best x ite: 149, best y ite: 73\n",
      "train finish\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "# 根据测试，如果目标得到最优xy而非对样本的无尽拟合，200次迭代足够了\n",
    "m_ite=5000\n",
    "\n",
    "#构造模型开始训练\n",
    "model1 = Mymodel()\n",
    "model2 = Mymodel()\n",
    "print(\"model created\")\n",
    "train(model1,model2,train_infor, train_input,eval_infor,eval_input,image_size, m_ite)\n",
    "print(\"train finish\")\n",
    "paddle.save(model1.state_dict(), model_save_dir+str(1))\n",
    "paddle.save(model2.state_dict(), model_save_dir+str(2))\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% finished\n",
      "12.5% finished\n",
      "25.0% finished\n",
      "37.5% finished\n",
      "50.0% finished\n",
      "62.5% finished\n",
      "75.0% finished\n",
      "87.5% finished\n",
      "100% finished\n"
     ]
    }
   ],
   "source": [
    "test_infor, test_input=get_test_image(image_size)\n",
    "test_infor.to_csv('test_infor.csv',index=None)\n",
    "test_input.to_csv('test_input.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n",
      "test_start\n"
     ]
    }
   ],
   "source": [
    "#开始测试\n",
    "model1 = Mymodel()\n",
    "model2 = Mymodel()\n",
    "print(\"model created\")\n",
    "param_dict1 = paddle.load(last_model_dir+'x')\n",
    "model1.load_dict(param_dict1)\n",
    "param_dict2 = paddle.load(last_model_dir+'y')\n",
    "model2.load_dict(param_dict2)\n",
    "\n",
    "test(model1,model2, test_infor, test_input ,image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结和一些讨论\n",
    "相对于之前的工作增加了验证集，并且将xy分开进行处理，但是提升的效果仍为有限，可见想要提高效果从网络结构下手更好。\n",
    "<br />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
